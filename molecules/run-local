#!/bin/bash

set -e

# Parse command line arguments
WORK_DIR=/tmp/cloudml-samples/molecules
MAX_DATA_FILES=5
while [[ $# -gt 0 ]]; do
  case $1 in
    --work-dir)
      WORK_DIR=$2
      shift
      ;;
    --max-data-files)
      MAX_DATA_FILES=$2
      shift
      ;;
    *)
      echo "error: unrecognized argument $1"
      exit 1
      ;;
  esac
  shift
done

# Wrapper function to print the command being run
function run {
  echo "$ $@"
  "$@"
}

# Extract the data files
echo '>> Extracting data'
run python data-extractor.py \
  --work-dir $WORK_DIR \
  --max-data-files $MAX_DATA_FILES
echo ''

# Preprocess the datasets
echo '>> Preprocessing'
run python preprocess.py \
  --work-dir $WORK_DIR
echo ''

# Train and evaluate the model
echo '>> Training'
run python trainer/task.py \
  --work-dir $WORK_DIR
echo ''

# Get the model path
EXPORT_DIR=$WORK_DIR/model/export
if [[ $EXPORT_DIR == gs://* ]]; then
  MODEL_DIR=$(gsutil ls -d $EXPORT_DIR/* | sort -r | head -n 1)
else
  MODEL_DIR=$(ls -d -1 $EXPORT_DIR/* | sort -r | head -n 1)
fi
echo "Model: $MODEL_DIR"
echo ''

# Make predictions via JSON requests
echo '>> JSON predictions'
run gcloud ml-engine local predict \
  --model-dir $MODEL_DIR \
  --json-instances sample-requests.json
echo ''

# Make batch predictions with full-stack preprocessing
echo '>> Full-stack batch prediction'
run python predict.py \
  --work-dir $WORK_DIR \
  --model-dir $MODEL_DIR \
  batch \
  --inputs-dir $WORK_DIR/data \
  --outputs-dir $WORK_DIR/predictions

# Display some sample predictions
if [[ $WORK_DIR == gs://* ]]; then
  gsutil cat $WORK_DIR/predictions/* | head -n 10
else
  head -n 10 $WORK_DIR/predictions/*
fi
