{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Serving TensorFlow models on AI Platform using R Interface\n",
    "## Overview\n",
    "\n",
    "This notebook illustrates how to use [R interface for TensorFlow](https://tensorflow.rstudio.com/) to build an ML model to estimate the baby's weight given a number of factors, using the [BigQuery natality dataset](https://console.cloud.google.com/bigquery?p=bigquery-public-data&d=samples&t=natality&page=table&_ga=2.99329886.-1705629017.1551465326&_gac=1.109796023.1561476396.CI2rz-z4hOMCFc6RhQods4oEXA). We use [AI Platform Training](https://cloud.google.com/ml-engine/docs/tensorflow/training-overview) to train the TensorFlow model at scale, and then use the [AI Platform Prediction](https://cloud.google.com/ml-engine/docs/tensorflow/prediction-overview) to serve the trained model for online predictions.\n",
    "\n",
    "R is one of the most widely used programming languages for statistical modeling, which has a large and active community of data scientists and ML professional. \n",
    "With over 10,000 packages in the open-source repository of CRAN, R caters to all statistical data analysis applications, ML, and visualisation.\n",
    "\n",
    "\n",
    "## Dataset\n",
    "The dataset used in this tutorial is natality data, which describes all United States births registered in the 50 States, the District of Columbia, and New York City from 1969 to 2008, with more than 137 million records.\n",
    "The dataset is available in [BigQuery public dataset](https://console.cloud.google.com/bigquery?p=bigquery-public-data&d=samples&t=natality&page=table&_ga=2.99329886.-1705629017.1551465326&_gac=1.109796023.1561476396.CI2rz-z4hOMCFc6RhQods4oEXA). We use the data extracted from BigQuery and stored as CSV in Cloud Storage (GCS) in the [Exploratory Data Analysis](01_EDA-with-R-and-BigQuery) notebook.\n",
    "\n",
    "In this notebook, we focus on Exploratory Data Analysis, while the goal is to predict the baby's weight given a number of factors about the pregnancy and the baby's mother.\n",
    "\n",
    "## Objective\n",
    "The goal of this tutorial is to:\n",
    "1. Create a TensorFlow premade Estimator trainer using R interface\n",
    "2. Train and export the Estimator on AI Platform Training using the cloudml APIs\n",
    "3. Deploy the exported model to AI Platform prediction using the cloudml APIs\n",
    "4. Invoke the deployed model API for predictions.\n",
    "\n",
    "\n",
    "## Costs\n",
    "This tutorial uses billable components of Google Cloud Platform (GCP):\n",
    "1. Create a TensorFlow premade Estimator trainer using R interface\n",
    "2. Train and export the Estimator on AI Platform Training using the cloudml APIs\n",
    "3. Deploy the exported model to AI Platform prediction using the cloudml APIs\n",
    "4. Invoke the deployed model API for predictions.\n",
    "5. Use the AI Platform Notebooks to drive the workflow.\n",
    "\n",
    "\n",
    "Learn about GCP pricing, use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "Install and import the required libraries. \n",
    "\n",
    "This may take several minutes if not installed already..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(c(\"tfestimators\", \"tfdatasets\", \"cloudml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tfestimators) # used for creating tensorflow estimators\n",
    "library(tfdatasets) # used for creating data input functions\n",
    "library(cloudml) # used for training and deploying models to AI Platform\n",
    "install_tensorflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your `PROJECT_ID`, `BUCKET_NAME`, and `REGION`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the project id\n",
    "PROJECT_ID <- \"r-on-gcp\"\n",
    "\n",
    "# Set yout GCS bucket\n",
    "BUCKET_NAME <- \"r-on-gcp\" \n",
    "\n",
    "# Set your training and model deployment region\n",
    "REGION <- 'us-central1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Building the TensorFlow Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Create feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical columns\n",
    "mother_age <- tf$feature_column$numeric_column(\"mother_age\")\n",
    "plurality <- tf$feature_column$numeric_column('plurality')\n",
    "gestation_weeks <- tf$feature_column$numeric_column('gestation_weeks')\n",
    "\n",
    "\n",
    "# categorical columns\n",
    "is_male <- tf$feature_column$categorical_column_with_vocabulary_list(\"is_male\", vocabulary_list = c(\"True\", \"False\"))\n",
    "mother_race <- tf$feature_column$categorical_column_with_vocabulary_list(\n",
    "    'mother_race', vocabulary_list = c('1', '2', '3', '4', '5', '6', '7', '8', '9', '18', '28', '38', '48', '58', '69', '78'))\n",
    "mother_married <- tf$feature_column$categorical_column_with_vocabulary_list('mother_married', c('True', 'False'))\n",
    "cigarette_use <- tf$feature_column$categorical_column_with_vocabulary_list('cigarette_use', c('True', 'False', 'None'))\n",
    "alcohol_use <- tf$feature_column$categorical_column_with_vocabulary_list('alcohol_use', c('True', 'False', 'None'))\n",
    "\n",
    "# extended feature columns\n",
    "cigarette_use_X_alcohol_use = tf$feature_column$crossed_column(c(\"cigarette_use\", \"alcohol_use\"), 9)\n",
    "mother_race_embedded = tf$feature_column$embedding_column(mother_race, 3)\n",
    "mother_age_bucketized = tf$feature_column$bucketized_column(mother_age, boundaries=c(18, 22, 28, 32, 36, 40, 42, 45, 50))  \n",
    "mother_race_X_mother_age_bucketized = tf$feature_column$crossed_column(c(mother_age_bucketized, \"mother_race\"),  120)   \n",
    "mother_race_X_mother_age_bucketized_embedded = tf$feature_column$embedding_column(mother_race_X_mother_age_bucketized, 5)\n",
    "    \n",
    "# wide and deep columns\n",
    "wide_columns <- feature_columns(\n",
    "    is_male, mother_race, plurality, mother_married, cigarette_use, alcohol_use, cigarette_use_X_alcohol_use, mother_age_bucketized) \n",
    "deep_columns <- feature_columns(\n",
    "    mother_age, gestation_weeks, mother_race_embedded, mother_race_X_mother_age_bucketized_embedded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Instantiate Estimator\n",
    "\n",
    "We use the premade [dnn_linear_combined_regressor](https://tensorflow.rstudio.com/tfestimators/reference/dnn_linear_combined_estimators.html). This is a [Wide & Deep](https://arxiv.org/abs/1606.07792) model that is useful for generic large-scale regression problems with sparse input features (e.g., categorical features with a large number of possible feature values) and dense input features (numerical features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'models/tf_babyweight_estimator'\n",
    "\n",
    "model <- dnn_linear_combined_regressor(\n",
    "    model_dir = model_dir,\n",
    "    linear_feature_columns = wide_columns,\n",
    "    dnn_feature_columns = deep_columns,\n",
    "    dnn_optimizer = \"Adagrad\",\n",
    "    linear_optimizer = \"Ftrl\",\n",
    "    dnn_hidden_units = c(64, 64),\n",
    "    dnn_activation_fn = \"relu\", \n",
    "    dnn_dropout = 0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Define data input functions\n",
    "If you run the [Exploratory Data Analysis](01_EDA-with-R-and-BigQuery) Notebook, you should have the **train_data.csv** and **eval_data.csv** files uploaded to GCS. You can download them to train your model locally using the following cell. However, if you have the files available locally, you can skip the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir.create(file.path('data'), showWarnings = FALSE)\n",
    "gcs_data_dir <- paste0(\"gs://\", BUCKET_NAME, \"/data/*_data.csv\")\n",
    "gsutil_exec(\"cp\", \"-r\", gcs_data_dir, \"data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data input function for training and evaluation, based on the data files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file <- \"data/train_data.csv\"\n",
    "eval_file <- \"data/eval_data.csv\"\n",
    "header <- c(\n",
    "    \"weight_pounds\", \n",
    "    \"is_male\", \"mother_age\", \"mother_race\", \"plurality\", \"gestation_weeks\", \n",
    "    \"mother_married\", \"cigarette_use\", \"alcohol_use\", \n",
    "    \"key\")\n",
    "types <- c(\n",
    "    \"double\", \n",
    "    \"character\", \"double\", \"character\", \"double\", \"double\", \n",
    "    \"character\", \"character\", \"character\", \n",
    "    \"character\")\n",
    "\n",
    "target <- \"weight_pounds\"\n",
    "key <- \"key\"\n",
    "features <- setdiff(header, c(target, key))\n",
    "\n",
    "data_input_fn <- function(data, batch_size, num_epochs = 1, shuffle = FALSE) {\n",
    "  input_fn(data, features = features, response = target, \n",
    "           batch_size = batch_size, shuffle = shuffle, num_epochs = num_epochs)\n",
    "}\n",
    "\n",
    "train_data <- read.table(train_file, col.names = header, sep=\",\", colClasses = types)\n",
    "eval_data <- read.table(eval_file, col.names = header, sep=\",\", colClasses = types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train, Evaluate, and Export the Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Train the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 2\n",
    "\n",
    "unlink(model_dir, recursive = TRUE)\n",
    "\n",
    "history <- train(\n",
    "    model, \n",
    "    input_fn = data_input_fn(train_data, batch_size = batch_size, num_epochs = num_epochs, shuffle = TRUE)\n",
    ")\n",
    "\n",
    "plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Evaluate the trained estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(\n",
    "    model, \n",
    "    input_fn = data_input_fn(eval_data, batch_size = batch_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Export trained estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_spec <- list()\n",
    "for (i in 1:length(header)) {\n",
    "    column <- header[i]\n",
    "    if (column %in% features) {\n",
    "        \n",
    "        default_value = 'NA'\n",
    "        column_type <- types[i]\n",
    "        \n",
    "        if (column_type != 'character'){\n",
    "            default_value = 0\n",
    "        }\n",
    "        \n",
    "        default_tensor <- tf$constant(value = default_value, shape = shape(1, 1))\n",
    "        feature_spec[[column]] <- tf$placeholder_with_default(\n",
    "            input = default_tensor, shape = shape(NULL, 1))\n",
    "    }   \n",
    "}  \n",
    "            \n",
    "serving_input_receiver_fn <- tf$estimator$export$build_raw_serving_input_receiver_fn(feature_spec)\n",
    "\n",
    "saved_model_dir = paste0(model_dir, '/export')\n",
    "export_savedmodel(model, saved_model_dir, serving_input_receiver_fn = serving_input_receiver_fn)\n",
    "print(paste(\"Model exported to:\", saved_model_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Submit a Training Job to AI Platform\n",
    "In order to train your TensorFlow estimator in at scale using AI Platform Training, you need to write your training implementation in a [model_trainer.R](src/tensorflow/model_trainer) file. The file includes the code in the previous cells to create, train, evaluate, and export the TensorFlow dnn_linear_combined_regressor model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install and load required packages\n",
    "install.packages(c(\"caret\", \"plumber\", \"rjson\", \"foreach\"))\n",
    "\n",
    "cloudml_train('src/tensorflow/model_trainer.R', region = REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name <- 'tf_babyweight_estimator'\n",
    "gcs_model_dir <- paste0(\"gs://\", BUCKET_NAME, \"/models/\", model_name)\n",
    "gsutil_exec(\"ls\", gcs_model_dir, echo = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deploy the trained model to AI Platform Prediction\n",
    "If you train your model using the model_trainer.R in AI Platform, it will upload the saved model to GCS. However, if you train your model locally and have your saved model locally, you need to upload it to GCS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 4.0. Upload the saved model to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name <- 'tf_babyweight_estimator'\n",
    "gcs_model_dir <- paste0(\"gs://\", BUCKET_NAME, \"/models/\", model_name)\n",
    "gsutil_exec(\"cp\", \"-r\", saved_model_dir, gcs_model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcloud_exec(\"ai-platform\", \"models\", \"list\")\n",
    "\n",
    "# Create model\n",
    "model_name <- 'tf_babyweight_estimator'\n",
    "gcloud_exec(\"ai-platform\", \"models\", \"create\", model_name, \"--regions\", REGION)\n",
    "\n",
    "# List models\n",
    "gcloud_exec(\"ai-platform\", \"models\", \"list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Create a model version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create version\n",
    "model_version <- 'v01'\n",
    "framework <- 'tensorflow'\n",
    "runtime_version <- '1.14'\n",
    "\n",
    "gcloud_exec(\"ai-platform\", \"versions\", \"create\", model_version, \n",
    "            \"--model\", model_name, \n",
    "            \"--framework\", framework,\n",
    "            \"--runtime-version\", runtime_version,\n",
    "            \"--origin\", gcs_model_dir\n",
    "           )\n",
    "\n",
    "# List versions\n",
    "gcloud_exec(\"ai-platform\", \"versions\", \"list\", \"--model\", model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Invoke the Model API for Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"rjson\")\n",
    "\n",
    "model_version <- 'v01'\n",
    "\n",
    "instances_string <- '\n",
    "[\n",
    "    {\n",
    "        \"is_male\": [\"TRUE\"],\n",
    "        \"mother_age\": [28],\n",
    "        \"mother_race\": [\"8\"],\n",
    "        \"plurality\": [1],\n",
    "        \"gestation_weeks\":  [18],\n",
    "        \"mother_married\": [\"TRUE\"],\n",
    "        \"cigarette_use\": [\"FALSE\"],\n",
    "        \"alcohol_use\": [\"FALSE\"]\n",
    "     }    \n",
    "]\n",
    "'\n",
    "\n",
    "instances <- jsonlite::fromJSON(instances_string, simplifyVector = FALSE)\n",
    "predictions <- cloudml_predict(instances, model_name, version = model_version, verbose = TRUE)\n",
    "print(paste(\"Estimated weight(s):\", predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Daniel Sparing & Khalid Salama\n",
    "\n",
    "---\n",
    "**Disclaimer**: This is not an official Google product. The sample code provided for an educational purpose.\n",
    "\n",
    "---\n",
    "\n",
    "Copyright 2019 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0.\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
