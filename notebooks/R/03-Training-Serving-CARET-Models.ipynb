{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Serving CARET models using AI Platform Custom Containers and Cloud Run\n",
    "## Overview\n",
    "\n",
    "This notebook illustrates how to use [CARET](https://topepo.github.io/caret/) R package to build an ML model to estimate the baby's weight given a number of factors, using the [BigQuery natality dataset](https://console.cloud.google.com/bigquery?p=bigquery-public-data&d=samples&t=natality&page=table&_ga=2.99329886.-1705629017.1551465326&_gac=1.109796023.1561476396.CI2rz-z4hOMCFc6RhQods4oEXA). We use [AI Platform Training](https://cloud.google.com/ml-engine/docs/tensorflow/training-overview) with **Custom Containers** to train the TensorFlow model at scale. Rhen use the [Cloud Run](https://cloud.google.com/run/docs/) to serve the trained model as a Web API for online predictions.\n",
    "\n",
    "R is one of the most widely used programming languages for statistical modeling, which has a large and active community of data scientists and ML professional. \n",
    "With over 10,000 packages in the open-source repository of CRAN, R caters to all statistical data analysis applications, ML, and visualisation.\n",
    "\n",
    "\n",
    "## Dataset\n",
    "The dataset used in this tutorial is natality data, which describes all United States births registered in the 50 States, the District of Columbia, and New York City from 1969 to 2008, with more than 137 million records.\n",
    "The dataset is available in [BigQuery public dataset](https://console.cloud.google.com/bigquery?p=bigquery-public-data&d=samples&t=natality&page=table&_ga=2.99329886.-1705629017.1551465326&_gac=1.109796023.1561476396.CI2rz-z4hOMCFc6RhQods4oEXA). We use the data extracted from BigQuery and stored as CSV in Cloud Storage (GCS) in the [Exploratory Data Analysis](01_EDA-with-R-and-BigQuery) notebook.\n",
    "\n",
    "In this notebook, we focus on Exploratory Data Analysis, while the goal is to predict the baby's weight given a number of factors about the pregnancy and the baby's mother.\n",
    "\n",
    "## Objective\n",
    "The goal of this tutorial is to:\n",
    "1. Create a CARET regression model\n",
    "2. Train the CARET model using on AI Platform Training with custom R container\n",
    "3. Implement a Web API wrapper to the trained model using Plumber R package\n",
    "4. Build Docker container image for the prediction Web API\n",
    "5. Deploy the prediction Web API container image model on Cloud Run\n",
    "6. Invoke the deployed Web API for predictions.\n",
    "7. Use the AI Platform Notebooks to drive the workflow.\n",
    "\n",
    "\n",
    "\n",
    "## Costs\n",
    "This tutorial uses billable components of Google Cloud Platform (GCP):\n",
    "1. Create a TensorFlow premade Estimator trainer using R interface\n",
    "2. Train and export the Estimator on AI Platform Training using the cloudml APIs\n",
    "3. Deploy the exported model to AI Platform prediction using the cloudml APIs\n",
    "4. Invoke the deployed model API for predictions.\n",
    "5. Use the AI Platform Notebooks to drive the workflow.\n",
    "\n",
    "\n",
    "Learn about GCP pricing, use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(c(\"caret\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret) # used to build a regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the project id\n",
    "PROJECT_ID <- \"r-on-gcp\"\n",
    "\n",
    "# Set yout GCS bucket\n",
    "BUCKET_NAME <- \"r-on-gcp\" \n",
    "\n",
    "# Set your training and model deployment region\n",
    "REGION <- 'europe-west1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Building a CARET Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load data\n",
    "\n",
    "If you run the [Exploratory Data Analysis](01_EDA-with-R-and-BigQuery) Notebook, you should have the **train_data.csv** and **eval_data.csv** files uploaded to GCS. You can download them to train your model locally using the following cell. However, if you have the files available locally, you can skip the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir.create(file.path('data'), showWarnings = FALSE)\n",
    "gcs_data_dir <- paste0(\"gs://\", BUCKET_NAME, \"/data/*_data.csv\")\n",
    "command <- paste(\"gsutil cp -r\", gcs_data_dir, \"data/\")\n",
    "print(command)\n",
    "system(command, intern = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file <- \"data/train_data.csv\"\n",
    "eval_file <- \"data/eval_data.csv\"\n",
    "header <- c(\n",
    "    \"weight_pounds\", \n",
    "    \"is_male\", \"mother_age\", \"mother_race\", \"plurality\", \"gestation_weeks\", \n",
    "    \"mother_married\", \"cigarette_use\", \"alcohol_use\", \n",
    "    \"key\")\n",
    "\n",
    "target <- \"weight_pounds\"\n",
    "key <- \"key\"\n",
    "features <- setdiff(header, c(target, key))\n",
    "\n",
    "train_data <- read.table(train_file, col.names = header, sep=\",\")\n",
    "eval_data <- read.table(eval_file, col.names = header, sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Train the model\n",
    "In this example, we will train an XGboost Tree model for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainControl <- trainControl(method = 'boot', number = 10)\n",
    "hyper_parameters <- expand.grid(\n",
    "    nrounds = 100,\n",
    "    max_depth = 6,\n",
    "    eta = 0.3,\n",
    "    gamma = 0,\n",
    "    colsample_bytree = 1,\n",
    "    min_child_weight = 1,\n",
    "    subsample = 1\n",
    ")\n",
    "  \n",
    "print('Training the model...')\n",
    "\n",
    "model <- train(\n",
    "    y=train_data$weight_pounds, \n",
    "    x=train_data[, features], \n",
    "    preProc = c(\"center\", \"scale\"),\n",
    "    method='xgbTree', \n",
    "    trControl=trainControl,\n",
    "    tuneGrid=hyper_parameters\n",
    ")\n",
    "\n",
    "print('Model is trained.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir <- \"models\"\n",
    "model_name <- \"caret_babyweight_estimator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the trained model\n",
    "dir.create(model_dir, showWarnings = FALSE)\n",
    "dir.create(file.path(model_dir, model_name), showWarnings = FALSE)\n",
    "saveRDS(model, file.path(model_dir, model_name, \"trained_model.rds\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Implementing a model prediction function\n",
    "This is an implementation of wrapper function to the model to perform prediction. The function expects a list of instances in a JSON format, and returns a list of predictions (estimated weights). This prediction function implementation will be used when serving the model as a Web API for online predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbtree <- readRDS(file.path(model_dir, model_name, \"trained_model.rds\"))\n",
    "\n",
    "estimate_babyweights <- function(instances_json){\n",
    "    library(\"rjson\")\n",
    "    instances <- jsonlite::fromJSON(instances_json)\n",
    "    df_instances <- data.frame(instances)\n",
    "    # fix data types\n",
    "    boolean_columns <- c(\"is_male\", \"mother_married\", \"cigarette_use\", \"alcohol_use\")\n",
    "    for(col in boolean_columns){\n",
    "        df_instances[[col]] <- as.logical(df_instances[[col]])\n",
    "    }\n",
    "    \n",
    "    estimates <- predict(xgbtree, df_instances)\n",
    "    return(estimates) \n",
    "}\n",
    "\n",
    "instances_json <- '\n",
    "[\n",
    "    {\n",
    "        \"is_male\": \"TRUE\",\n",
    "        \"mother_age\": 28,\n",
    "        \"mother_race\": 8,\n",
    "        \"plurality\": 1,\n",
    "        \"gestation_weeks\":  28,\n",
    "        \"mother_married\": \"TRUE\",\n",
    "        \"cigarette_use\": \"FALSE\",\n",
    "        \"alcohol_use\": \"FALSE\"\n",
    "     },\n",
    "    {\n",
    "        \"is_male\": \"FALSE\",\n",
    "        \"mother_age\": 38,\n",
    "        \"mother_race\": 18,\n",
    "        \"plurality\": 1,\n",
    "        \"gestation_weeks\":  28,\n",
    "        \"mother_married\": \"TRUE\",\n",
    "        \"cigarette_use\": \"TRUE\",\n",
    "        \"alcohol_use\": \"TRUE\"\n",
    "     }\n",
    "]\n",
    "'\n",
    "\n",
    "estimate <- round(estimate_babyweights(instances_json), digits = 2)\n",
    "print(paste(\"Estimated weight(s):\", estimate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Submit a Training Job to AI Platform with Custom Containers\n",
    "In order to train your CARET model in at scale using AI Platform Training, you need to implement your training logic in an R script file, containerize it in a Docker image, and submit the Docker image to AI Platform Training.\n",
    "\n",
    "The [src/caret/training](src/caret/training) directory includes the following code files:\n",
    "1. [model_trainer.R](src/caret/training/model_trainer.R) - This is the implementation of the CARET model training logic.\n",
    "1. [Dockerfile](src/caret/training/Dockerfile) - This is the definition of the Docker container image to run the **model_trainer.R** script.\n",
    "\n",
    "To submit the training job with the custom container to AI Platform, you need to do the following steps:\n",
    "1. set your PROJECT_ID and BUCKET_NAME in training/model_trainer.R, and PROJECT_ID in training/Dockerfile so that the first line reads \"FROM gcr.io/[PROJECT_ID]/caret_base\"\n",
    "2. **Build** a Docker container image with that runs the model_trainer.R\n",
    "3. **Push** the Docker container image to **Container Registry**.\n",
    "4. **Submit** an **AI Platform Training** job with the **custom container**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Build and Push the Docker container image.\n",
    "#### A - Build base image\n",
    "This can take several minutes ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base image\n",
    "base_image_url <- paste0(\"gcr.io/\", PROJECT_ID, \"/caret_base\")\n",
    "print(base_image_url)\n",
    "\n",
    "setwd(\"src/caret\")\n",
    "getwd()\n",
    "\n",
    "print(\"Building the base Docker container image...\")\n",
    "command <- paste0(\"docker build -f Dockerfile --tag \", base_image_url, \" ./\")\n",
    "print(command)\n",
    "system(command, intern = TRUE)\n",
    "\n",
    "print(\"Pushing the baseDocker container image...\")\n",
    "command <- paste0(\"gcloud docker -- push \", base_image_url)\n",
    "print(command)\n",
    "system(command, intern = TRUE)\n",
    "\n",
    "setwd(\"../..\")\n",
    "getwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B - Build trainer image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image_url <- paste0(\"gcr.io/\", PROJECT_ID, \"/\", model_name, \"_training\")\n",
    "print(training_image_url)\n",
    "\n",
    "setwd(\"src/caret/training\")\n",
    "getwd()\n",
    "\n",
    "print(\"Building the Docker container image...\")\n",
    "command <- paste0(\"docker build -f Dockerfile --tag \", training_image_url, \" ./\")\n",
    "print(command)\n",
    "system(command, intern = TRUE)\n",
    "\n",
    "print(\"Pushing the Docker container image...\")\n",
    "command <- paste0(\"gcloud docker -- push \", training_image_url)\n",
    "print(command)\n",
    "system(command, intern = TRUE)\n",
    "\n",
    "setwd(\"../../..\")\n",
    "getwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C- Verifying uploaded images to Container Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command <- paste0(\"gcloud container images list --repository=gcr.io/\", PROJECT_ID)\n",
    "system(command, intern = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Submit an AI Plaform Training job with the custom container. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name <- paste0(\"train_caret_contrainer_\", format(Sys.time(), \"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "command = paste0(\"gcloud beta ml-engine jobs submit training \", job_name, \n",
    "  \" --master-image-uri=\", training_image_url,\n",
    "  \" --scale-tier=BASIC\", \n",
    "  \" --region=\", REGION\n",
    ")\n",
    "print(command)\n",
    "\n",
    "system(command, intern = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the trained model in GCS after the job finishes\n",
    "model_name <- 'caret_babyweight_estimator'\n",
    "gcs_model_dir <- paste0(\"gs://\", BUCKET_NAME, \"/models/\", model_name)\n",
    "command <- paste0(\"gsutil ls \", gcs_model_dir)\n",
    "system(command, intern = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deploy the trained model to Cloud Run\n",
    "In order to serve the trained CARET model as a Web API, you need to wrap it with a prediction function, as serve this prediction function as a REST API. Then you containerize this Web API and deploy it in Cloud Run.\n",
    "\n",
    "The [src/caret/serving](src/caret/serving) directory includes the following code files:\n",
    "1. [model_prediction.R](src/caret/serving/model_prediction.R) - This script downloads the trained model from GCS and loads (only once). It includes **estimate** function, which accepts instances in JSON format, and return the of baby weight estimate for each instance.\n",
    "2. [model_api.R](src/caret/serving/model_prediction.R) - This is a [plumber](https://www.rplumber.io/) Web API that runs  **model_prediction.R**.\n",
    "3. [Dockerfile](src/caret/serving/Dockerfile) - This is the definition of Docker container image that runs the **model_api.R**\n",
    "\n",
    "To deploy the prediction Web API to Cloud Run, you need to do the following steps:\n",
    "1. set your PROJECT_ID and BUCKET_NAME in serving/model_prediction.R, and PROJECT_ID in serving/Dockerfile so that the first line reads \"FROM gcr.io/[PROJECT_ID]/caret_base\"\n",
    "2. **Build** the Docker container image for the prediction API.\n",
    "3. **Push** the Docker container image to **Cloud Registry**.\n",
    "4. Enable the Cloud Run API if not enabled yet, click \"Enable\" at https://console.developers.google.com/apis/api/run.googleapis.com/overview .\n",
    "5. **Deploy** the Docker container to **Cloud Run**. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 4.0. Upload the trained model to GCS\n",
    "If you train your model using the model_trainer.R in AI Platform, it will upload the saved model to GCS. However, if you only train your model locally and have your saved model locally, you need to upload it to GCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name <- 'caret_babyweight_estimator'\n",
    "gcs_model_dir = paste0(\"gs://\", BUCKET_NAME, \"/models/\", model_name, \"/\")\n",
    "command <- paste0(\"gsutil cp -r models/\", model_name ,\"/* \",gcs_model_dir)\n",
    "print(command)\n",
    "system(command, intern = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Build and Push prediction Docker container image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_image_url <- paste0(\"gcr.io/\", PROJECT_ID, \"/\", model_name, \"_serving\")\n",
    "print(serving_image_url)\n",
    "\n",
    "setwd(\"src/caret/serving\")\n",
    "getwd()\n",
    "\n",
    "print(\"Building the Docker container image...\")\n",
    "command <- paste0(\"docker build -f Dockerfile --tag \", serving_image_url, \" ./\")\n",
    "print(command)\n",
    "system(command, intern = TRUE)\n",
    "\n",
    "print(\"Pushing the Docker container image...\")\n",
    "command <- paste0(\"gcloud docker -- push \", serving_image_url)\n",
    "print(command)\n",
    "system(command, intern = TRUE)\n",
    "\n",
    "setwd(\"../../..\")\n",
    "getwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command <- paste0(\"gcloud container images list --repository=gcr.io/\", PROJECT_ID)\n",
    "system(command, intern = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Deploy prediction container to Cloud Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_name <- \"caret-babyweight-estimator\"\n",
    "command <- paste(\n",
    "    \"gcloud beta run deploy\", service_name,\n",
    "    \"--image\", serving_image_url,\n",
    "    \"--platform managed\",\n",
    "    \"--allow-unauthenticated\",\n",
    "    \"--region\", REGION\n",
    ")\n",
    "\n",
    "print(command)\n",
    "system(command, intern = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Invoke the Model API for Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the **caret-babyweight-estimator** service is deployed to Cloud Run:\n",
    "1. Go to Cloud Run in the [Cloud Console](https://console.cloud.google.com/run/).\n",
    "2. Select the **caret-babyweight-estimator** service.\n",
    "3. Copy the service URL, and use it to update the **url** variable in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update to the deployed service URL\n",
    "url <- \"https://caret-babyweight-estimator-lbcii4x34q-uc.a.run.app/\"\n",
    "endpoint <- \"estimate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_json <- '\n",
    "[\n",
    "    {\n",
    "        \"is_male\": \"TRUE\",\n",
    "        \"mother_age\": 28,\n",
    "        \"mother_race\": 8,\n",
    "        \"plurality\": 1,\n",
    "        \"gestation_weeks\":  28,\n",
    "        \"mother_married\": \"TRUE\",\n",
    "        \"cigarette_use\": \"FALSE\",\n",
    "        \"alcohol_use\": \"FALSE\"\n",
    "     },\n",
    "    {\n",
    "        \"is_male\": \"FALSE\",\n",
    "        \"mother_age\": 38,\n",
    "        \"mother_race\": 18,\n",
    "        \"plurality\": 1,\n",
    "        \"gestation_weeks\":  28,\n",
    "        \"mother_married\": \"TRUE\",\n",
    "        \"cigarette_use\": \"TRUE\",\n",
    "        \"alcohol_use\": \"TRUE\"\n",
    "     }\n",
    "]\n",
    "'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"xml2\")\n",
    "library(\"httr\")\n",
    "full_url <- paste0(url, endpoint)\n",
    "response <- POST(full_url, body = instances_json)\n",
    "estimates <- content(response)\n",
    "print(paste(\"Estimated weight(s):\", estimate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Daniel Sparing & Khalid Salama\n",
    "\n",
    "---\n",
    "**Disclaimer**: This is not an official Google product. The sample code provided for an educational purpose.\n",
    "\n",
    "---\n",
    "\n",
    "Copyright 2019 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0.\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
