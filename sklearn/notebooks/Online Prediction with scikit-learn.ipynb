{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Prediction with scikit-learn on Google Cloud Machine Learning Engine\n",
    "This notebook uses the [Census Income Data Set](https://archive.ics.uci.edu/ml/datasets/Census+Income) to create a simple model, train the model, upload the model to Cloud Machine Learning Engine (ML Engine), and lastly use the model to make predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to bring your model to ML Engine\n",
    "Getting your model ready for predictions can be done in 5 steps:\n",
    "1. Save your model to a file\n",
    "1. Upload the saved model to [Google Cloud Storage](https://cloud.google.com/storage)\n",
    "1. Create a model resource on ML Engine\n",
    "1. Create a model version (linking your scikit-learn model)\n",
    "1. Make an online prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "Before you jump in, let’s cover some of the different tools you’ll be using to get online prediction up and running on ML Engine. \n",
    "\n",
    "[Google Cloud Platform](https://cloud.google.com/) lets you build and host applications and websites, store data, and analyze data on Google's scalable infrastructure.\n",
    "\n",
    "[Cloud ML Engine](https://cloud.google.com/ml-engine/) is a managed service that enables you to easily build machine learning models that work on any type of data, of any size.\n",
    "\n",
    "[Google Cloud Storage](https://cloud.google.com/storage/) (GCS) is unified object storage for developers and enterprises, from live data serving to data analytics/ML to data archiving.\n",
    "\n",
    "[The Cloud SDK](https://cloud.google.com/sdk/) is a set of tools for Cloud Platform. It contains gcloud, gsutil, and bq, which you can use to access Google Compute Engine, Google Cloud Storage, Google BigQuery, and other products and services from the command-line.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Setup\n",
    "* [Create a project on GCP](https://cloud.google.com/resource-manager/docs/creating-managing-projects)\n",
    "* [Create a Google Cloud Storage Bucket](https://cloud.google.com/storage/docs/quickstart-console)\n",
    "* [Enable Cloud Machine Learning Engine and Compute Engine APIs](https://console.cloud.google.com/flows/enableapi?apiid=ml.googleapis.com,compute_component&_ga=2.217405014.1312742076.1516128282-1417583630.1516128282)\n",
    "\n",
    "These variables will be needed for the following steps.\n",
    "\n",
    "** Replace: **\n",
    "* `PROJECT_ID <YOUR_PROJECT_ID>` - with your project's id. Use the PROJECT_ID that matches your Google Cloud Platform project.\n",
    "* `BUCKET_ID <YOUR_BUCKET_ID>` - with the bucket id you created above.\n",
    "* `MODEL_NAME <YOUR_MODEL_NAME>` - with your model name, such as '`census`'\n",
    "* `VERSION <YOUR_VERSION>` - with your version name, such as '`v1`'\n",
    "* `REGION <REGION>` - select a region from [here](https://cloud.google.com/ml-engine/docs/regions) or use the default '`us-central1`'. The region is where the model will be deployed.\n",
    "* `INPUT_DATA_FILE <data.json>` - a JSON file that contains the data used as input to your model’s predict method. (You'll create this in the code below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PROJECT_ID=true-ability-192918\n"
     ]
    }
   ],
   "source": [
    "%env PROJECT_ID true-ability-192918"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BUCKET_ID=true-ability-192918\n"
     ]
    }
   ],
   "source": [
    "%env BUCKET_ID true-ability-192918"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MODEL_NAME=census\n"
     ]
    }
   ],
   "source": [
    "%env MODEL_NAME census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: VERSION_NAME=v1\n"
     ]
    }
   ],
   "source": [
    "%env VERSION_NAME v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: REGION=us-central1\n"
     ]
    }
   ],
   "source": [
    "%env REGION us-central1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: INPUT_DATA_FILE=data.json\n"
     ]
    }
   ],
   "source": [
    "%env INPUT_DATA_FILE data.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data\n",
    "The [Census Income Data Set](https://archive.ics.uci.edu/ml/datasets/Census+Income) that this sample\n",
    "uses for training is hosted by the [UC Irvine Machine Learning\n",
    "Repository](https://archive.ics.uci.edu/ml/datasets/). We have hosted the data\n",
    "on Google Cloud Storage in a slightly cleaned form:\n",
    "\n",
    " * Training file is `adult.data`\n",
    " * Evaluation file is `adult.test`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disclaimer\n",
    "This dataset is provided by a third party. Google provides no representation,\n",
    "warranty, or other guarantees about the validity or any other aspects of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 3881k  100 3881k    0     0  2733k      0  0:00:01  0:00:01 --:--:-- 2733k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1956k  100 1956k    0     0  2034k      0 --:--:-- --:--:-- --:--:-- 2033k\n"
     ]
    }
   ],
   "source": [
    "# Create a directory to hold the data\n",
    "! mkdir census_data\n",
    "\n",
    "# Download the data\n",
    "! curl https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data --output census_data/adult.data\n",
    "! curl https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test --output census_data/adult.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Train/Save the model \n",
    "First, the data is loaded into a numpy array that can be used by scikit-learn. Then a simple model is created and fit against the training data. Lastly, sklearn's built in version of joblib is used to save the model to a file that can be uploaded to ML Engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Define the format of your input data including unused columns (These are the columns from the census data files)\n",
    "COLUMNS = (\n",
    "    'age',\n",
    "    'workclass',\n",
    "    'fnlwgt',\n",
    "    'education',\n",
    "    'education-num',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'capital-gain',\n",
    "    'capital-loss',\n",
    "    'hours-per-week',\n",
    "    'native-country',\n",
    "    'income-level'\n",
    ")\n",
    "\n",
    "# Categorical columns are columns that need to be turned into a numerical value to be used by scikit-learn\n",
    "CATEGORICAL_COLUMNS = (\n",
    "    'workclass',\n",
    "    'education',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'native-country'\n",
    ")\n",
    "\n",
    "\n",
    "# Load the training census dataset\n",
    "with open('./census_data/adult.data', 'r') as train_data:\n",
    "    raw_training_data = pd.read_csv(train_data, header=None, names=COLUMNS)\n",
    "# Remove the column we are trying to predict ('income-level') from our features list\n",
    "train_features = raw_training_data.drop('income-level', axis=1)\n",
    "# Create our training labels list\n",
    "train_labels = (raw_training_data['income-level'] == ' >50K')\n",
    "\n",
    "\n",
    "# Load the test census dataset\n",
    "with open('./census_data/adult.test', 'r') as test_data:\n",
    "    raw_testing_data = pd.read_csv(test_data, names=COLUMNS, skiprows=1)\n",
    "# Remove the column we are trying to predict ('income-level') from our features list\n",
    "test_features = raw_testing_data.drop('income-level', axis=1)\n",
    "# Create our training labels list\n",
    "test_labels = (raw_testing_data['income-level'] == ' >50K.')\n",
    "\n",
    "\n",
    "# Convert the categorical columns to a numerical value in both the training and testing dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoders = {col:LabelEncoder() for col in CATEGORICAL_COLUMNS}\n",
    "\n",
    "for col in CATEGORICAL_COLUMNS:\n",
    "    train_features[col] = encoders[col].fit_transform(train_features[col])\n",
    "\n",
    "for col in CATEGORICAL_COLUMNS:\n",
    "    test_features[col] = encoders[col].fit_transform(test_features[col])\n",
    "\n",
    "\n",
    "# Create and train a classifier\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(train_features, train_labels)\n",
    "\n",
    "# Export the classifier to a file\n",
    "joblib.dump(classifier, 'model.joblib')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Upload the model\n",
    "Next, you'll need to upload the model to your project's storage bucket in GCS. To use your model with ML Engine, it needs to be uploaded to Google Cloud Storage (GCS). This step takes your local ‘model.joblib’ file and uploads it GCS via the Cloud SDK using gsutil.\n",
    "\n",
    "Note: The exact file name of of the exported model you upload to GCS is important! Your model must be named  “model.joblib”, “model.pkl”, or “model.bst” with respect to the library you used to export it. This restriction ensures that the model will be safely reconstructed later by using the same technique for import as was used during export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./model.joblib [Content-Type=application/octet-stream]...\n",
      "-\n",
      "Operation completed over 1 objects/6.5 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "! gsutil cp ./model.joblib gs://$BUCKET_ID/model.joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Create a model resource\n",
    "Cloud ML Engine organizes your trained models using model and version resources. A Cloud ML Engine model is a container for the versions of your machine learning model. For more information on model resources and model versions look [here](https://cloud.google.com/ml-engine/docs/deploying-models#creating_a_model_version). \n",
    "\n",
    "At this step, you create a container that you can use to hold several different versions of your actual model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ml engine model [projects/true-ability-192918/models/census].\r\n"
     ]
    }
   ],
   "source": [
    "! gcloud ml-engine models create $MODEL_NAME --regions us-central1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Create a model version\n",
    "\n",
    "Now it’s time to get your model online and ready for predictions. The model version requires a few components as specified [here](https://cloud.google.com/ml-engine/reference/rest/v1/projects.models.versions#Version).\n",
    "\n",
    "* __name__ - The name specified for the version when it was created. This will be the `VERSION_NAME` variable you declared at the beginning.\n",
    "* __deployment Uri__ (curl) or __origin__ (gcloud) - The Google Cloud Storage location of the trained model used to create the version. This is the bucket that you uploaded the model to with your `BUCKET_ID`\n",
    "* __runtime__ version - The Google Cloud ML runtime version to use for this deployment. This is set to 1.4\n",
    "* __framework__ - The framework specifies if you are using: `TENSORFLOW`, `SCIKIT_LEARN`, `XGBOOST`. This is set to `SCIKIT_LEARN`\n",
    "\n",
    "Note: It can take several minutes for you model to be available.\n",
    "\n",
    "Note: If you require a feature of scikit-learn that isn’t available in the publicly released version yet, you can specify “runtimeVersion”: “HEAD” instead, and that would get the latest version of scikit-learn available from the github repo. Otherwise the following versions will be used:\n",
    "* scikit-learn: 0.19.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"name\": \"projects/true-ability-192918/operations/create_census_v1-1517440102159\",\r\n",
      "  \"metadata\": {\r\n",
      "    \"@type\": \"type.googleapis.com/google.cloud.ml.v1.OperationMetadata\",\r\n",
      "    \"createTime\": \"2018-01-31T23:08:22Z\",\r\n",
      "    \"operationType\": \"CREATE_VERSION\",\r\n",
      "    \"modelName\": \"projects/true-ability-192918/models/census\",\r\n",
      "    \"version\": {\r\n",
      "      \"name\": \"projects/true-ability-192918/models/census/versions/v1\",\r\n",
      "      \"deploymentUri\": \"gs://true-ability-192918/\",\r\n",
      "      \"createTime\": \"2018-01-31T23:08:22Z\",\r\n",
      "      \"etag\": \"tc3SVp7707A=\",\r\n",
      "      \"framework\": \"SCIKIT_LEARN\"\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "! curl -X POST -H \"Content-Type: application/json\" \\\n",
    "   -d '{\"name\": \"'$VERSION_NAME'\", \"deploymentUri\": \"gs://'$BUCKET_ID'/\", \"runtimeVersion\": \"1.4\", \"framework\": \"SCIKIT_LEARN\"}' \\\n",
    "   -H \"Authorization: Bearer `gcloud auth print-access-token`\" \\\n",
    "    https://ml.googleapis.com/v1/projects/$PROJECT_ID/models/$MODEL_NAME/versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Make an online prediction\n",
    "It’s time to make an online prediction with your newly deployed model. Before you begin, you'll need to take some of the test data and prepare it, so that the test data can be used by the deployed model.\n",
    "\n",
    "To get online predictions, the data needs to be converted from a numpy array to a json array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show a person that makes <=50K:\n",
      "\tFeatures: [25, 4, 226802, 1, 7, 4, 7, 3, 2, 1, 0, 0, 40, 38] --> Label: False\n",
      "\n",
      "Show a person that makes >50K:\n",
      "\tFeatures: [28, 2, 336951, 7, 12, 2, 11, 0, 4, 1, 0, 0, 40, 38] --> Label: True\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data = []\n",
    "for i in range(len(test_features)):\n",
    "  data.append([])\n",
    "  for col in COLUMNS[:-1]: # Ignore the 'income-level' column as it is not in the feature set.\n",
    "    # Convert from numpy integers to standard integers\n",
    "    data[i].append(int(np.uint64(test_features[col][i]).item()))\n",
    "\n",
    "# Write the test data to a json file\n",
    "with open('data.json', 'w') as outfile:\n",
    "  json.dump(data, outfile)\n",
    "\n",
    "# Get one person that makes <=50K and one that makes >50K to test our model.\n",
    "print('Show a person that makes <=50K:')\n",
    "print('\\tFeatures: {0} --> Label: {1}\\n'.format(data[0], test_labels[0]))\n",
    "\n",
    "with open('less_than_50K.json', 'w') as outfile:\n",
    "  json.dump(data[0], outfile)\n",
    "\n",
    "  \n",
    "print('Show a person that makes >50K:')\n",
    "print('\\tFeatures: {0} --> Label: {1}'.format(data[2], test_labels[2]))\n",
    "\n",
    "with open('more_than_50K.json', 'w') as outfile:\n",
    "  json.dump(data[2], outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use gcloud to make online predictions\n",
    "Use the two people (as seen in the table) gathered in the previous step for the gcloud predictions.\n",
    "\n",
    "| **Person** | age | workclass | fnlwgt | education | education-num | marital-status | occupation |\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:\n",
    "| **1** | 25| 4 | 226802 | 1 | 7 | 4 | 7 |\n",
    "| **2** | 28| 2 | 336951 | 7 | 12 | 2 | 11 |\n",
    "\n",
    "| **Person** | relationship | race | sex | capital-gain | capital-loss | hours-per-week | native-country || (Label) income-level|\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||:-:\n",
    "| **1** | 3 | 2 | 1 | 0 | 0 | 40 | 38 || False (<=50K) |\n",
    "| **2** | 0 | 4 | 1 | 0 | 0 | 40 | 38 || True (>50K) |\n",
    "\n",
    "\n",
    "Creating a model version can take several minutes, check the status of your model version to see if it is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME  DEPLOYMENT_URI             STATE\r\n",
      "v1    gs://true-ability-192918/  CREATING\r\n"
     ]
    }
   ],
   "source": [
    "! gcloud ml-engine versions list --model $MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME  DEPLOYMENT_URI             STATE\r\n",
      "v1    gs://true-ability-192918/  READY\r\n"
     ]
    }
   ],
   "source": [
    "! gcloud ml-engine versions list --model $MODEL_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model with an online prediction using the data of a person who makes <=50K.\n",
    "\n",
    "Note: If you see an error, the model from Part 4 may not be created yet as it takes several minutes for a new model version to be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\r\n"
     ]
    }
   ],
   "source": [
    "! gcloud ml-engine predict --model $MODEL_NAME --version $VERSION_NAME --json-instances less_than_50K.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model with an online prediction using the data of a person who makes >50K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True]\r\n"
     ]
    }
   ],
   "source": [
    "! gcloud ml-engine predict --model $MODEL_NAME --version $VERSION_NAME --json-instances more_than_50K.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Python to make online predictions\n",
    "Test the model with the entire test set and print out some of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-01-31 23:13:42,137] {discovery.py:863} INFO - URL being requested: POST https://ml.googleapis.com/v1/projects/true-ability-192918/models/census/versions/v1:predict?alt=json\n",
      "Prediction: False\tLabel: False\n",
      "Prediction: False\tLabel: False\n",
      "Prediction: True\tLabel: True\n",
      "Prediction: True\tLabel: True\n",
      "Prediction: False\tLabel: False\n",
      "Prediction: False\tLabel: False\n",
      "Prediction: False\tLabel: False\n",
      "Prediction: True\tLabel: True\n",
      "Prediction: False\tLabel: False\n",
      "Prediction: False\tLabel: False\n"
     ]
    }
   ],
   "source": [
    "import googleapiclient.discovery\n",
    "import os\n",
    "\n",
    "PROJECT_ID = os.environ['PROJECT_ID']\n",
    "VERSION_NAME = os.environ['VERSION_NAME']\n",
    "MODEL_NAME = os.environ['MODEL_NAME']\n",
    "\n",
    "service = googleapiclient.discovery.build('ml', 'v1')\n",
    "name = 'projects/{}/models/{}'.format(PROJECT_ID, MODEL_NAME)\n",
    "name += '/versions/{}'.format(VERSION_NAME)\n",
    "\n",
    "response = service.projects().predict(\n",
    "    name=name,\n",
    "    body={'instances': data}\n",
    ").execute()\n",
    "\n",
    "if 'error' in response:\n",
    "  print response['error']\n",
    "else:\n",
    "  responses = response['predictions']\n",
    "  # Print the first 10 responses\n",
    "  for i, response in enumerate(responses[:10]):\n",
    "    print 'Prediction: {}\\tLabel: {}'.format(response, test_labels[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
